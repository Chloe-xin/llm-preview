{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e8e3d2",
   "metadata": {},
   "source": [
    "本节学习大纲\n",
    "  - 基本概念科普\n",
    "  - 提示词技巧\n",
    "    - 技巧一：角色扮演 (Role Prompting)\n",
    "    - 技巧二：分步思考 (CoT)\n",
    "    - 技巧三：格式约束 (Output Schema)\n",
    "    - 技巧四：少样本 (Few-Shot)\n",
    "  - 提示词书写实例\n",
    "    - 润色论文\n",
    "    - 语言学习\n",
    "    - 总结：如何设计一个好的提示词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb597443",
   "metadata": {},
   "source": [
    "在前两节课中，我们学习了大模型的环境配置和两种使用方式（云端使用/本地部署），但“会使用”≠“使用得好”。\n",
    "\n",
    "很多同学在使用中可能会发现：\n",
    "\n",
    "- 让模型润色一下论文，它却加了很多不需要的夸张修辞；\n",
    "\n",
    "- 让它生成小红书爆款标题，它却像老干部写公文--又臭又长。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7290e3b",
   "metadata": {},
   "source": [
    "其实，问题不在模型，而在“沟通方式”。\n",
    "\n",
    "大模型像一位知识渊博却刚毕业的天才学霸——他读过整个互联网上的海量知识，却不懂你的任务场景、输出格式、细节要点。提示词工程（Prompt Engineering）就是写给这位学霸的“说明书”：\n",
    "\n",
    "- 告诉他“你是谁、要做什么、做到什么程度”；\n",
    "\n",
    "- 给他“示例、边界、格式”；\n",
    "\n",
    "- 再用迭代和评估，把模糊需求变成可复现的“代码级”指令。\n",
    "\n",
    "所以这节课，我们来学习如何通过提示词过程让大模型更好的理解和完成我们下达的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878efc2f",
   "metadata": {},
   "source": [
    "## 3.1 基本概念科普\n",
    "\n",
    "在正式学习这个技术之前，我们需要先弄清两个词：**提示词（Prompt）**与**提示词工程**。\n",
    "\n",
    "1. 什么是提示词？  \n",
    "提示词就是我们在与大模型对话时输入的那段文字。它可以是简单的一句话，也可以是一段详细的指令加示例。模型会根据这段文字决定“接下来要输出什么”。因此，提示词本质上是人与模型之间的“接口”，它的作用就像与你交谈的伙伴提出的问题一样：清晰明确的提示能让模型更准确理解需求并生成有用回复，反之模糊的提示可能导致模型迷惑或请求更多信息​。\n",
    "\n",
    "2. 什么是提示词工程？  \n",
    "提示词工程是设计和优化提示词的系统性方法。它包含三部分：  \n",
    "    - 设计：用清晰、结构化的语言告诉模型“任务是什么、输出格式是什么、边界在哪里”；  \n",
    "    - 实验：通过多组小样本快速对比，找出效果最好的写法；  \n",
    "    - 迭代：随着任务需求的变化，持续微调提示词，而无需重新训练模型。  \n",
    "\n",
    "3. 我们为什么要写好提示词？  \n",
    "大模型不会“猜”我们的需求。提示词写得好，模型一次就能给出可用的结果，省下反复调试的时间；写得不好，即使最先进的模型也会出现答非所问、格式错乱或输出冗长的问题。好的 Prompt 能把模型能力直接转化为可落地的生产力，既减少 token 消耗，也降低后期人工校正的成本。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d827f0c",
   "metadata": {},
   "source": [
    "## 3.2 提示词技巧"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d08aaf",
   "metadata": {},
   "source": [
    "### 3.2.1 书写提示词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631f97a",
   "metadata": {},
   "source": [
    "怎样才算一条“好”的提示词？尽管不同任务对“好”的定义略有差异，但业界普遍认可以下三条共性标准：\n",
    "\n",
    "1. 语义清晰：要求措辞通俗、结构简洁，既能让模型准确理解意图，也能让普通阅读者一目了然。  \n",
    "   典型示例：过度依赖特殊符号或晦涩缩写，偶能奏效，却牺牲了可读性；且一旦模型升级，这些“暗号”还可能失效。\n",
    "\n",
    "2. 通用性强：在同类任务中，只需替换主体词即可迁移复用，无需大幅改写。  \n",
    "   典型示例：一段用于生成科幻小说的提示框架，把“太空舰队”替换成“民国商战”，仍能输出高质量文本。\n",
    "\n",
    "3. 结果稳定：同一提示词在多次调用下，输出分布集中、质量波动小。  \n",
    "   典型示例：某些提示词十次调用仅一次达标，稳定性不足，将直接拖累生产效率。\n",
    "\n",
    "总而言之，清晰、通用且稳定的提示词，才是真正可落地、可复用、可信赖的生产力工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c4e34",
   "metadata": {},
   "source": [
    "那如何动手写出一条“好”提示词？我们可以先套用下面这个“万用公式”：\n",
    "\n",
    "提示词 = 任务【必选】＋生成主体【必选】＋细节【可选】＋形式【可选】\n",
    "\n",
    "1. 任务（Task）——告诉模型“做什么”  \n",
    "   用动词起句，精准锁定操作类型：撰写、改写、总结、翻译、生成、解释、充当……  \n",
    "   例：请撰写 / 请充当 / 请总结\n",
    "\n",
    "2. 生成主体（Subject）——告诉模型“对谁做”  \n",
    "   直指核心对象，越具体越好。  \n",
    "   例：一篇关于狗不理包子的广告文案 / 一则中华传统童话\n",
    "\n",
    "3. 细节（Details）——告诉模型“做到什么程度”  \n",
    "   可叠加多个维度：受众、语气、风格、关键词、情感取向、长度限制等。  \n",
    "   例：内容积极向上，与狗狗相关，加入 emoji 点缀，800 字左右\n",
    "\n",
    "4. 形式（Format）——告诉模型“以什么形态交付”  \n",
    "   可指定排版、语言、载体或代码格式。  \n",
    "   例：Markdown 表格 / 粤语 / Python 代码 / 分镜脚本\n",
    "\n",
    "把四块内容按顺序拼接，就能在 30 秒内生成一条既清晰又完整的提示词。\n",
    "\n",
    "示范：请你**充当讲故事的人**（任务），创作一篇**具有中华特色、内容积极向上且与狗狗有关**（细节）的**童话故事**（生成主体），**用 Markdown 分章节排版，总字数 600–800 字**（形式）。”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03175b",
   "metadata": {},
   "source": [
    "### 3.2.2 优化提示词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0afba50",
   "metadata": {},
   "source": [
    "学会正确恰当的提示词技巧能够帮助我们提升提示词的有效性。我们来通过下面的例子直观感受一下使用了没使用提示词技巧和使用了之后的区别：\n",
    "\n",
    "- 无提示词技巧：请帮我写一篇 800 字的《红岩》心得体会。\n",
    "\n",
    "- 有提示词技巧：请以大一学生的身份，在完成学院组织的阅读《红岩》活动后，写一篇 800 字的 【心得体会】。要文笔细腻、词藻高级，内容的结尾要有升华点，并且需要与作为新时代青年的身份做结合。\n",
    "\n",
    "对比两条提示词指令，我们可以清晰地看到：无提示词技巧时，模型只能获得“主题 + 字数”两个最粗粒度的信息，最终产出的文章大概率是泛泛而谈、缺乏场景感与情感深度。加入提示词技巧后，指令额外给出了“身份、情境、文风、结构、内容要求”五个维度的限定。模型因此能够精准模拟一名大一新生的真实心境，语言更具画面感，论述也自然落到“新时代青年的使命”这一高阶立意上。\n",
    "\n",
    "所以，恰当的提示词就像把我们的诉求写到一张具体详实的图纸上输送给模型，模型按图施工，结果自然更合我们的心意。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad445f8a",
   "metadata": {},
   "source": [
    "那我们怎么通过提示词技巧来优化好我们的提示词呢？提示词书写的技巧其实并不固定，不同的模型对相同的提示词也许会有天差地别的反应，但我们常说一句话：“Garbage In, Garbage Out” (如果输入的是垃圾，那么输出的也会是垃圾)。你给AI的指令越模糊，它的回答就越可能偏离你的预期。所以我们需要将提示词写的清晰又简洁，来将模型的能力最大化。\n",
    "\n",
    "下面介绍四个常用的提示词技巧：\n",
    "\n",
    "1. **技巧一：角色扮演 (Role Prompting)**\n",
    "\n",
    "    作用：告诉AI“你是谁”，它就调用相应的知识库和表达方式。\n",
    "\n",
    "    用法：开头明确设定角色 (你现在是...)。角色越具体、越专业越好 (e.g., “资深半导体工艺工程师” 优于 “懂芯片的人”)。\n",
    "\n",
    "    举例：“你现在是《物理评论快报》(Physical Review Letters) 的资深审稿人。请严格按该期刊标准，指出我这段关于拓扑绝缘体输运性质的论述在理论推导严谨性和实验数据关联性上存在的3个主要不足。”\n",
    "\n",
    "2. **技巧二：分步思考 (CoT)**\n",
    "\n",
    "    作用：让AI“把思考过程写出来”。对于逻辑推导、数学证明、算法设计、故障排查等复杂任务至关重要，能显著提高答案正确率。\n",
    "\n",
    "    用法：明确指令 请一步步思考/推导/解释，并可以结构化引导 (如 1)... 2)... 3)...)。\n",
    "\n",
    "    举例：“给我这道数学题的解法。请你一步一步思考。”\n",
    "\n",
    "3. **技巧三：格式约束 (Output Schema)**\n",
    "\n",
    "    作用；让AI输出程序可读、可直接使用的结构化数据 (JSON, XML, YAML, Markdown Table等)，避免自由文本的解析麻烦。\n",
    "\n",
    "    用法；明确指定格式 (返回JSON/XML/Markdown表格)，并定义好键(Key)和预期值类型。\n",
    "\n",
    "    举例：“请你设计三个保护环境的宣传语，并以json的格式返回：```json\\n{'text1': xxx,\\n'text2': xxx,\\n'text3': xxx}```”\n",
    "\n",
    "4. **技巧四：少样本 (Few-Shot)**\n",
    "\n",
    "    作用：通过2-3个高质量示例，让AI瞬间理解你想要的风格、深度、语气、格式、术语级别。\n",
    "\n",
    "    用法：下面是[数量]个例子：[示例1] [示例2] [示例3] 请模仿以上风格/格式，完成：[你的任务]。\n",
    "\n",
    "    举例：请你帮我起一个好听的群聊昵称，按照如下风格：‘身家万亿稻妻堂堂邱雯大小姐’、‘海阔暴风吸入辣椒水好喝到翘jiojio’、‘可口咸豆脑甜月饼甜粽香迷糊了’\n",
    "\n",
    "以上四个是一些常用且好用的提示词技巧，可以单独使用，但我们在实际中往往会组合起来使用，实现 1 + 1 > 2 的效果！\n",
    "\n",
    "大家也可以针对不同的任务试试不同的写法，看看在自己的任务上哪种方式效果更好~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186f8d9",
   "metadata": {},
   "source": [
    "## 3.3 提示词书写实例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e357f",
   "metadata": {},
   "source": [
    "学完了上述理论部分，我们在[硅基流动（SiliconFlow）](https://cloud.siliconflow.cn/i/ybUFvmqK)平台上调用 **Qwen3-8B** 模型（在chatper2章节中的2.1节介绍了调用方法），通过下面三个例子来具体的看看如何书写提示词和使用提示词技巧吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083ce17",
   "metadata": {},
   "source": [
    "### 3.3.1 润色论文\n",
    "\n",
    "论文的撰写具有严明的格式要求。假设我们在论文中引用到了 Transformer 模型，需要对其进行介绍。我们的初稿是这样的：\n",
    "\n",
    "“transformer 是一种用于序列到序列的深度学习模型，相较于传统的 rnn 和 lstm ，它引入了注意力机制，能够更好的关注到序列数据中的语义信息，同时解决了长距离依赖问题，并且能够并行处理。”\n",
    "\n",
    "可以看到里面的英文名词书写不规范（首字母未大写等），用词比较粗糙、不严谨。现在我们让大模型对其进行润色，如果我们不用任何提示词书写技巧，结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e62f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "普通提问的结果：\n",
      "\n",
      "\n",
      "Transformer模型是一种基于深度学习的序列建模架构，其核心创新在于引入了自注意力机制（self-attention mechanism）。相较于传统的循环神经网络（RNN）和长短期记忆网络（LSTM），Transformer通过全局依赖建模有效缓解了传统序列模型中存在的长距离依赖问题。同时，该模型具备并行处理能力，相较于RNN/LSTM的序列化处理显著提升了计算效率与训练速度。这种结构设计使其在自然语言处理、机器翻译等序列生成任务中展现出优越的性能表现。\n",
      "\n",
      "（说明：在保持原意的基础上，主要做了以下学术化处理：\n",
      "1. 规范了专业术语的大小写（RNN/LSTM）和全称表述\n",
      "2. 增加了\"全局依赖建模\"等技术性描述\n",
      "3. 补充了\"计算效率与训练速度\"等量化优势\n",
      "4. 加入应用场景说明，增强论述完整性\n",
      "5. 使用\"创新在于\"、\"具备\"等学术用语\n",
      "6. 优化了句子结构，使其更符合论文写作的逻辑性和严谨性）\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=\"your api key\",     # 记得替换成自己的 API Key\n",
    "                base_url=\"https://api.siliconflow.cn/v1\")\n",
    "\n",
    "prompt = '''请将下面这段话润色成学术论文风格：\n",
    "'transformer 是一种用于序列到序列的深度学习模型，相较于传统的 rnn 和 lstm ，它引入了注意力机制，能够更好的关注到序列数据中的语义信息，同时解决了长距离依赖问题，并且能够并行处理。'\n",
    "'''\n",
    "\n",
    "response_without_skill = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ],\n",
    "    max_tokens=1024,\n",
    "    temperature=0.9,  # 温度系数，越接近 1 模型输出越随机，越接近 0 模型输出越固定\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(f\"普通提问的结果：\\n{response_without_skill.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f6949",
   "metadata": {},
   "source": [
    "可以看到以上结果中大模型虽然优化了用词，但整体句式表述较为臃肿，不太符合论文简洁、严谨的风格。\n",
    "\n",
    "现在我们按照万用公式定义好任务（润色）、生成主体（论文）、细节（符合严谨简明的学术风格），加上前面学习的提示词书写技巧中的“角色扮演”、“少样本”技巧试试看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "带有技巧的提问的结果：\n",
      "\n",
      "\n",
      "Transformer模型是一种面向序列到序列任务的深度学习架构，相较于传统的RNN和LSTM，其引入了注意力机制，从而有效提取序列数据中的语义信息，并缓解了长距离依赖问题，同时具备显著的并行处理能力。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=\"your api key\",     # 记得替换成自己的 API Key\n",
    "                base_url=\"https://api.siliconflow.cn/v1\")\n",
    "\n",
    "prompt = '''角色：你是 IEEE 会议论文的资深语言编辑。  \n",
    "任务：将下列段落润色为符合 IEEE 标准的学术中文。  \n",
    "要求：  \n",
    "1. 用词正式、简洁；  \n",
    "2. 保持原意，增强逻辑；  \n",
    "3. 仅返回润色后的段落，不附加解释。  \n",
    "\n",
    "示例1：  \n",
    "原文：最近，BERT 在很多任务上都表现得很好。  \n",
    "润色：近期，BERT 在多项任务中均展现出卓越性能。  \n",
    "\n",
    "示例2：  \n",
    "原文：我们发现这个方法比 baseline 更好。  \n",
    "润色：实验结果表明，所提方法显著优于基线。\n",
    "\n",
    "待润色段落：\n",
    "transformer 是一种用于序列到序列的深度学习模型，相较于传统的 rnn 和 lstm，它引入了注意力机制，能够更好的关注到序列数据中的语义信息，同时解决了长距离依赖问题，并且能够并行处理。\n",
    "'''\n",
    "\n",
    "response_with_skill = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ],\n",
    "    max_tokens=1024,\n",
    "    temperature=0.9,\n",
    "    stream=False\n",
    ")\n",
    "print(f\"带有技巧的提问的结果：\\n{response_with_skill.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8f2d25",
   "metadata": {},
   "source": [
    "对比两种结果，可以看到加了技巧后模型的润色结果更加简洁，逻辑性更强。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac860e",
   "metadata": {},
   "source": [
    "### 3.3.2 语言学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c545e",
   "metadata": {},
   "source": [
    "接下来我们再学习一个让大模型教我们学英语的例子，对比不带技巧和带技巧的 prompt 下模型的效果。\n",
    "\n",
    "下面是不带技巧，直接对模型进行提问的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e5d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "普通提问的结果：\n",
      "\n",
      "\n",
      "以下是三句实用的关于“点餐”的英文表达：\n",
      "\n",
      "1. **\"I’d like to try something new, do you have any recommendations?\"**  \n",
      "   （我想尝试一些新东西，您有什么推荐吗？）  \n",
      "   *用于向服务员询问菜品推荐，显得礼貌且自然。*\n",
      "\n",
      "2. **\"I’ll have the [dish name], please.\"**  \n",
      "   （我想要一份[菜品名称]。）  \n",
      "   *用于明确点餐，注意将[dish name]替换为具体菜品，如\"grilled salmon\"（烤三文鱼）或\"spaghetti bolognese\"（意大利肉酱面）。*\n",
      "\n",
      "3. **\"Could I have this dish without [ingredient] or with [additional item]?\"**  \n",
      "   （这道菜可以不加[食材]或加[其他配料]吗？）  \n",
      "   *用于提出饮食限制或额外需求，如\"without cheese\"（不加奶酪）或\"with extra sauce\"（加更多酱汁）。*\n",
      "\n",
      "**小贴士：**  \n",
      "- 用 \"Could I have...\" 会比 \"I want to...\" 更委婉。  \n",
      "- 询问推荐时，可以说 \"What’s your favorite dish?\"（您最推荐的菜品是什么？）或 \"Do you have any specialties?\"（你们有什么特色菜？）。  \n",
      "- 确认订单时可用 \"Just to confirm, I ordered...\"（确认一下，我点了...）。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=\"your api key\",     # 记得替换成自己的 API Key\n",
    "                base_url=\"https://api.siliconflow.cn/v1\")\n",
    "\n",
    "prompt = '''教我三句关于“点餐”的英文。'''\n",
    "\n",
    "response_without_skill = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ],\n",
    "    max_tokens=1024,\n",
    "    temperature=0.9,  # 温度系数，越接近 1 模型输出越随机，越接近 0 模型输出越固定\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(f\"普通提问的结果：\\n{response_without_skill.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffead2f",
   "metadata": {},
   "source": [
    "如果我们加上前面学习的“角色扮演”、“分布思考”、“格式约束”技巧，就会得到更加贴切、清晰、规范的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40eefb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "带有技巧的提问的结果：\n",
      "\n",
      "\n",
      "场景1：进入餐厅询问菜单  \n",
      "口语1：I’d like to see the menu, please.  \n",
      "翻译1：请给我看看菜单。  \n",
      "讲解1：  \n",
      "- **I’d** 是 \"I would\" 的缩写，表示委婉礼貌的请求。\"would\" 在口语中常用于表达间接或客气的语气。  \n",
      "- **see the menu** 是动词短语，\"see\" 表示查看，\"the menu\" 指菜单。  \n",
      "- **please** 放在句末，强调礼貌，是英语中常见的礼貌助动词。  \n",
      "- 整体结构为：情态动词（would）+ 动词原形（see）+ 宾语（the menu），符合英语请求句的语法规则。  \n",
      "\n",
      "场景2：点餐时描述食物偏好  \n",
      "口语2：I’ll have the steak, medium rare.  \n",
      "翻译2：我要一份中等火候的牛排。  \n",
      "讲解2：  \n",
      "- **I’ll** 是 \"I will\" 的缩写，表示决定或承诺。\"will\" 在口语中常用于表达即时的意愿。  \n",
      "- **the steak** 是名词短语，特指牛排。  \n",
      "- **medium rare** 是形容词短语，指烹饪程度（中等偏生）。  \n",
      "- **have** 是核心动词，表示“点/要”食物，搭配名词（the steak）构成完整表达。  \n",
      "- 同时，**medium rare** 作为复合形容词，中间用连字符连接，这是英语中描述烹饪程度的固定用法。  \n",
      "\n",
      "场景3：结账时要求账单  \n",
      "口语3：Could I have the check, please?  \n",
      "翻译3：请给我账单，谢谢。  \n",
      "讲解3：  \n",
      "- **Could** 是 \"can\" 的委婉形式，用于礼貌地提出请求或建议。  \n",
      "- **have the check** 中的 \"check\" 指账单（正式用法），口语中更常说 \"bill\"，但 \"check\" 在某些地区（如美国）仍常见。  \n",
      "- **please** 与场景1类似，加强礼貌语气。  \n",
      "- 整体结构为：情态动词（could）+ 动词原形（have）+ 宾语（the check），符合英语请求句的语法规则。  \n",
      "- 注意：**Could** 也可以用于询问许可，例如 \"Could I order this?\" 但此处是请求行动，需区分语境。  \n",
      "\n",
      "---\n",
      "\n",
      "**实用小贴士**  \n",
      "1. 在点餐时，用 **\"I’d like to order...\"** 比 **\"I want to order...\"** 更显礼貌。  \n",
      "2. 描述食物时，需注意形容词顺序（如 **size/color/temperature**），例如：\"a large, black coffee with no sugar\"。  \n",
      "3. **\"Check\"** 与 **\"bill\"** 的区别：正式场合用 **bill**，餐厅服务可能更倾向 **check**；但两者均可通用。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=\"your api key\",     # 记得替换成自己的 API Key\n",
    "                base_url=\"https://api.siliconflow.cn/v1\")\n",
    "\n",
    "prompt = '''角色：\n",
    "你是一名英语水平超高的大学英语老师，擅长辅导学生学习英语口语。\n",
    "任务：\n",
    "现在请你教我三个关于“点餐”的常用的地道英语口语。你需要先思考最常见的场景是什么，然后告诉我地道的表达是什么，再告诉我它的中文意思，最后给我讲解其中的语法知识。\n",
    "输出格式：\n",
    "场景1：xx\n",
    "口语1：xx\n",
    "翻译1：xx\n",
    "讲解1：xx\n",
    "'''\n",
    "\n",
    "response_with_skill = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ],\n",
    "    max_tokens=1024,\n",
    "    temperature=0.9,  # 温度系数，越接近 1 模型输出越随机，越接近 0 模型输出越固定\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(f\"带有技巧的提问的结果：\\n{response_with_skill.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea5060",
   "metadata": {},
   "source": [
    "在告诉模型更多有用的信息后，模型返回的结果会更加符合我们期望的效果。\n",
    "\n",
    "不过大家在书写 prompt 时，也一定要注意清晰、简洁的定义任务需求，避免给模型过多的无用信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbbc2c3",
   "metadata": {},
   "source": [
    "### 3.3.3 结语\n",
    "\n",
    "经过学习以上的例子，相信大家已经初步有了一些写好 prompt 心得和经验。写好一条 prompt，本质上是把人类意图翻译成模型可执行的“程序”。当你熟练运用“任务—主体—细节—形式”这一最小公式后，再复杂的场景也能被拆解成四个可填空的位置，像搭积木一样快速拼装。最后再根据任务的特性，使用一些提示词技巧来让提示词更有效。\n",
    "\n",
    "下一次打开对话框时，不妨先写下四行字：“\n",
    "做什么？对谁做？要做到哪一步？要以什么形态交？”\n",
    "当这四问都有答案，模型便不再是黑箱，而是你手中最听话的笔。\n",
    "\n",
    "最后，请坦然接受 “初稿即完美”的罕见——每一次不理想的输出，都是模型在向你揭示其认知的边界。这正是迭代的价值：以模型反馈为镜，反照 Prompt 中的模糊与不足，进而持续精炼你的指令。将优化 Prompt 视为一个动态对话和学习过程，你不仅能获得更理想的结果，更能深刻理解并解锁模型的真正潜力。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
